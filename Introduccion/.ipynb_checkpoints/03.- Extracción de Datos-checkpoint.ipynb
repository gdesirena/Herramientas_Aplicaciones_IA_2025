{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#000047; padding: 30px; border-radius: 10px; color: white; text-align: center;\">\n",
    "    <img src='Figures/alinco.png' style=\"height: 100px; margin-bottom: 10px;\"/>\n",
    "    <h1>Extracci√≥n de Datos de Diferentes Fuentes</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **extracci√≥n de datos** es el proceso de obtener informaci√≥n relevante desde diversas fuentes y formatos, como archivos de texto, hojas de c√°lculo, bases de datos, im√°genes, archivos web, APIs, entre otros. En la actualidad, los datos se encuentran dispersos y almacenados en m√∫ltiples formas, por lo que saber c√≥mo acceder, limpiar y transformar estos datos es una habilidad fundamental.\n",
    "\n",
    "#### ¬øPor qu√© es importante la extracci√≥n de datos?\n",
    "\n",
    "- Permite **integrar informaci√≥n** de diferentes sistemas y plataformas.\n",
    "- Es el primer paso para el **an√°lisis de datos** y la toma de decisiones basada en evidencia.\n",
    "- Facilita la **automatizaci√≥n** de procesos y la actualizaci√≥n constante de informaci√≥n.\n",
    "- Es esencial para la **preparaci√≥n de datos** en proyectos de ciencia de datos e inteligencia artificial.\n",
    "\n",
    "En proyectos de **Inteligencia Artificial (IA)**, la calidad y diversidad de los datos es clave para entrenar modelos robustos y precisos. La extracci√≥n de datos permite:\n",
    "\n",
    "- **Construir datasets** a partir de fuentes reales y actualizadas.\n",
    "- **Preprocesar y limpiar** la informaci√≥n antes de alimentar algoritmos de machine learning.\n",
    "- **Enriquecer modelos** combinando datos estructurados (tablas, bases de datos) y no estructurados (texto, im√°genes, audio).\n",
    "- **Automatizar la recolecci√≥n** de datos para sistemas de IA en producci√≥n.\n",
    "\n",
    "Dominar las t√©cnicas de extracci√≥n de datos te permitir√° abordar problemas complejos, crear soluciones inteligentes y aprovechar el potencial de la IA en cualquier √°rea profesional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e6f2ff; border-left:4px solid #000047; padding:10px;\">\n",
    "En este notebook aprender√°s a extraer datos desde archivos CSV, Excel, texto, JSON, XML, im√°genes, HTML y SHP, utilizando Python y sus principales librer√≠as.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamos la ruta de los archivos en una variable\n",
    "ruta='Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos Excel y CSV\n",
    "\n",
    "Los archivos Excel (`.xlsx`, `.xls`) y CSV (`.csv`) son formatos tabulares ampliamente utilizados para almacenar datos estructurados. Python, a trav√©s de la librer√≠a `pandas`, permite leer y manipular estos archivos de manera sencilla y eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv(ruta+'df_tabla2.csv')\n",
    "print('Contenido del archivo CSV:')\n",
    "print(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos de texto\n",
    "### De texto a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.read_fwf` de pandas se utiliza para leer archivos de texto con columnas de ancho fijo (fixed-width formatted lines) y cargarlos en un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracci√≥n a partir de texto separado por tabular\n",
    "pd.read_fwf(ruta+'texto_2.txt',header=None) # No se puede especificar el separador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_table` de pandas se utiliza para leer archivos de texto delimitados (por defecto, separados por tabulaciones) y cargarlos en un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table(ruta+'texto_2.txt',header=None) # sep='\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracci√≥n a partir de texto separado por comas\n",
    "pd.read_table(ruta+'texto_1.txt',sep=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table(ruta+'texto_1.txt',sep=' ',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(ruta+'texto_2.txt',header=None,sep='\\t') # sep=','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversi√≥n de archivo a variable\n",
    "file=open(ruta+'texto_3.txt')     # Abrir...\n",
    "texto=file.read()\n",
    "file.close()                      # ...despues cerrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ocurre un error durante la ejecuci√≥n, la variable file se cierra siempre:\n",
    "with open(ruta+'texto_3.txt') as file:\n",
    "  texto=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos cada palabra de la variable de texto\n",
    "texto.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto.split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expresiones regulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las <b>expresiones regulares</b> son patrones que permiten buscar, extraer, validar y manipular texto de manera flexible y eficiente. Son esenciales para limpiar datos, extraer informaci√≥n y validar formatos en archivos de texto.\n",
    "\n",
    "### Caracteres y operadores b√°sicos\n",
    "\n",
    "| S√≠mbolo | Significado | Ejemplo |\n",
    "|---------|-------------|---------|\n",
    "| `.`     | Cualquier car√°cter | `a.b` encuentra 'acb', 'aab', etc. |\n",
    "| `\\d`   | D√≠gito (0-9) | `\\d\\d` encuentra dos d√≠gitos |\n",
    "| `\\w`   | Car√°cter alfanum√©rico | `\\w+` encuentra palabras |\n",
    "| `\\s`   | Espacio en blanco | `\\s+` encuentra espacios |\n",
    "| `*`     | Cero o m√°s repeticiones | `ab*` encuentra 'a', 'ab', 'abb', ... |\n",
    "| `+`     | Una o m√°s repeticiones | `ab+` encuentra 'ab', 'abb', ... |\n",
    "| `?`     | Cero o una repetici√≥n | `ab?` encuentra 'a', 'ab' |\n",
    "| `^`     | Inicio de l√≠nea | `^Hola` encuentra l√≠neas que empiezan con 'Hola' |\n",
    "| `$`     | Fin de l√≠nea | `mundo$` encuentra l√≠neas que terminan con 'mundo' |\n",
    "| `[abc]` | Cualquier car√°cter a, b o c | `[aeiou]` encuentra vocales |\n",
    "| `( )`   | Agrupaci√≥n | `(abc)+` encuentra 'abc', 'abcabc', ... |\n",
    "\n",
    "### Funciones principales en Python (`re`)\n",
    "\n",
    "- `re.search(patron, texto)`: Busca el patr√≥n en el texto y devuelve el primer resultado.\n",
    "- `re.match(patron, texto)`: Verifica si el patr√≥n coincide al inicio del texto.\n",
    "- `re.findall(patron, texto)`: Devuelve todas las coincidencias del patr√≥n.\n",
    "- `re.sub(patron, reemplazo, texto)`: Reemplaza coincidencias por otro texto.\n",
    "\n",
    "### Ejemplo: Buscar correos electr√≥nicos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "texto_correo = \"Mi correo es gdesirena@outlook.mx pero anteriormente usaba gdesirena@gmail.com\"\n",
    "patron = r\"\\w+@\\w+\\.\\w+\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Extraer dominios de correos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominios = re.findall(r'@([\\w\\.-]+)', texto_correo)\n",
    "print('Dominios encontrados:', dominios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Buscar fechas en formato DD/MM/AAAA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_fechas = 'algunas fechas importantes son 15/09/2023 y 01/01/2024.' \n",
    "fechas = re.findall(r'\\b\\d{2}/\\d{2}/\\d{4}\\b', texto_fechas)\n",
    "print('Fechas encontradas:', fechas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Validar n√∫meros de tel√©fono\n",
    "\n",
    "Busca n√∫meros en formato internacional (+52 33 1234 5678):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_tel = 'Mi n√∫mero es +52 33 1234 5678 y el de mi amigo es +52 55 8765 4321.'\n",
    "patron_tel = r'\\+\\d{2}\\s\\d{2}\\s\\d{4}\\s\\d{4}'\n",
    "telefonos = re.findall(patron_tel, texto_tel)\n",
    "print('Tel√©fonos encontrados:', telefonos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Reemplazo de texto\n",
    "\n",
    "Reemplaza todos los d√≠gitos por 'X':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'Mi clave es 1234 y mi usuario es user01.'\n",
    "nuevo_texto = re.sub(r'\\d', 'X', texto)\n",
    "print(nuevo_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Conteo de palabras usando regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = re.split(r'\\W', texto)\n",
    "S = set(L)\n",
    "S.discard('')\n",
    "d = {}\n",
    "for palabra in S:\n",
    "    d[palabra] = len(re.findall(palabra, texto, flags=re.I))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "\n",
    "Busca todas las palabras que empiezan con la letra 'u' en el texto anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu c√≥digo aqu√≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "Extrae todos los n√∫meros de una cadena de texto y convi√©rtelos a enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu c√≥digo aqu√≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursos √∫tiles\n",
    "\n",
    "- [regex101.com](https://regex101.com/) - expresiones regulares en l√≠nea.\n",
    "- [Documentaci√≥n oficial de re](https://docs.python.org/3/library/re.html)\n",
    "\n",
    "<div style=\"background-color:#e6f2ff; border-left:4px solid #000047; padding:10px;\">\n",
    "Las expresiones regulares son una herramienta poderosa para la limpieza y extracci√≥n de datos en proyectos de IA y ciencia de datos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A partir de la funci√≥n\n",
    "pd.read_excel(ruta+'API_SI.POV.DDAY_DS2_en_excel_v2_1930012.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la clase ExcelFile\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A partir de la clase\n",
    "obj=ExcelFile(ruta+'API_SI.POV.DDAY_DS2_en_excel_v2_1930012.xls')\n",
    "obj.parse() # Importa la primera p√°gina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El formato JSON (JavaScript Object Notation) es ampliamente utilizado para el intercambio de datos, especialmente en aplicaciones web y APIs. Python incluye la librer√≠a est√°ndar `json` para leer y manipular archivos JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_data = '{\"personas\": [{\"nombre\": \"Ana\", \"edad\": 23}, {\"nombre\": \"Luis\", \"edad\": 31}]}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json['categories'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El formato XML es com√∫n para el intercambio de datos estructurados. Python ofrece la librer√≠a est√°ndar `xml.etree.ElementTree` para analizar y extraer informaci√≥n de archivos XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_data = '''\n",
    "<personas>\n",
    "  <persona>\n",
    "    <nombre>Ana</nombre>\n",
    "    <edad>23</edad>\n",
    "  </persona>\n",
    "  <persona>\n",
    "    <nombre>Luis</nombre>\n",
    "    <edad>31</edad>\n",
    "  </persona>\n",
    "</personas>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = ET.fromstring(xml_data)\n",
    "print('Personas extra√≠das del archivo XML:')\n",
    "for persona in root.findall('persona'):\n",
    "    nombre = persona.find('nombre').text\n",
    "    edad = persona.find('edad').text\n",
    "    print(f'Nombre: {nombre}, Edad: {edad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ejemplo con tabla_1.xml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_1=ET.parse(ruta+'tabla_1.xml')\n",
    "raiz=archivo_1.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nodo in raiz:\n",
    "    print(nodo.attrib,nodo.text,nodo.tag)\n",
    "    for sn in nodo:\n",
    "        print(sn.attrib,sn.text,sn.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_2=ET.parse(ruta+'tabla_2.xml')\n",
    "root=archivo_2.getroot()\n",
    "for nodo in root:\n",
    "    print(nodo.tag,nodo.attrib,nodo.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nodo in root:\n",
    "    for subn in nodo:\n",
    "        print(subn.tag,subn.attrib,subn.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraer los datos de tabla_1.xml\n",
    "d={}\n",
    "for nodo in raiz:\n",
    "    d[nodo.tag]=[]\n",
    "for nodo in raiz:\n",
    "    d[nodo.tag].append(nodo.attrib['name'])\n",
    "for nodo in raiz:\n",
    "    for sn in nodo:\n",
    "        d[sn.tag]=[]\n",
    "for nodo in raiz:\n",
    "    for sn in nodo:\n",
    "        d[sn.tag].append(sn.text)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df_1 = pd.DataFrame(columns = columnas)\n",
    "for nodo in raiz:\n",
    "  L = []\n",
    "  L.append(nodo.attrib['name'])\n",
    "  for sn in nodo:\n",
    "    L.append(sn.text)\n",
    "  df_1 = df_1.append(pd.DataFrame([L], columns=columnas), ignore_index=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo=ET.parse(ruta+'tabla_2.xml')\n",
    "raiz=archivo.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=[]\n",
    "for n in raiz.findall('documents/document'):\n",
    "    d={}\n",
    "    d[n.tag]=n.text\n",
    "    for k,v in n.attrib.items():\n",
    "        d[k]=v\n",
    "    L.append(d)\n",
    "pd.DataFrame(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo='IFC-Subscriptions-and-Voting-Power-of-Member-Count.xml'\n",
    "file=ET.parse(ruta+archivo)\n",
    "root=file.getroot()\n",
    "\n",
    "for nodo in root:\n",
    "    for snodo in nodo:\n",
    "        print(snodo.tag,snodo.attrib,snodo.text)\n",
    "        for ssnodo in snodo:\n",
    "            print(ssnodo.tag,ssnodo.attrib,ssnodo.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos SHP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los archivos Shapefile (`.shp`) son un formato est√°ndar para almacenar informaci√≥n geoespacial vectorial. La librer√≠a `geopandas` permite leer y manipular estos archivos de manera sencilla. Un Shapefile suele estar acompa√±ado de otros archivos como `.shx` y `.dbf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda !pip !conda\n",
    "%pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df = gpd.read_file('COVID_INDIA_POC-shp/COVID_INDIA_POC.shp')\n",
    "g_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "g_df.plot(\n",
    "    ax=ax,\n",
    "    column=g_df.columns[0],  # Cambia por la columna que quieras destacar\n",
    "    cmap='viridis',\n",
    "    edgecolor='black',\n",
    "    legend=True\n",
    ")\n",
    "ax.set_title('COVID_INDIA_POC', fontsize=12)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer un archivo HTML local\n",
    "with open(ruta+'ejemplo.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "print(html_content[:500])  # Muestra los primeros 500 caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install beautifulsoup4 #Instalar BeautifulSoup si es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar HTML con BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Extraer el t√≠tulo de la p√°gina\n",
    "titulo = soup.title.string\n",
    "print('T√≠tulo de la p√°gina:', titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer los enlaces de la p√°gina\n",
    "enlaces = soup.find_all('a')\n",
    "for enlace in enlaces:\n",
    "    print(enlace.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install requests # Instalar requests si es necesario\n",
    "import requests\n",
    "\n",
    "url = 'https://www.python.org/'\n",
    "response = requests.get(url)\n",
    "web_html = response.text\n",
    "\n",
    "# Analizar el HTML descargado\n",
    "soup_web = BeautifulSoup(web_html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup_web.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ejemplo sencillo webscraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    " \n",
    "url = \"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener un dataframe con la informaci√≥n de los productos\n",
    "products = []\n",
    "\n",
    "for price_tag in soup.find_all(\"h4\", string=lambda s: s and s.strip().startswith(\"$\")):\n",
    "    # El nombre del producto es la cadena que sigue despu√©s del tag <a> despu√©s del precio\n",
    "    product_link = price_tag.find_next(\"a\")\n",
    "    if not product_link:\n",
    "        continue\n",
    "    product_name = product_link.text.strip()\n",
    "    product_url = product_link[\"href\"]\n",
    "    # La descripci√≥n es el siguien tag <p> despu√©s de la liga del producto\n",
    "    description_tag = product_link.find_next(\"p\")\n",
    "    description = description_tag.text.strip() if description_tag else \"\"\n",
    "    # Los numero de reviews van despu√©s de <div> \n",
    "    reviews_tag = product_link.find_next(string=lambda s: s and \"review\" in s)\n",
    "    try:\n",
    "        reviews = int(reviews_tag.strip().split()[0])\n",
    "    except Exception:\n",
    "        reviews = None\n",
    "    # Precio\n",
    "    try:\n",
    "        price = float(price_tag.text.strip().replace(\"$\", \"\"))\n",
    "    except Exception:\n",
    "        price = None\n",
    " \n",
    "    products.append({\n",
    "        \"Product Name\": product_name,\n",
    "        \"Price\": price,\n",
    "        \"Description\": description,\n",
    "        \"Reviews\": reviews,\n",
    "        \"Product URL\": product_url\n",
    "    })\n",
    " \n",
    "df = pd.DataFrame(products)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos im√°gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las im√°genes RGB almacenan informaci√≥n de color en tres canales: Rojo (R), Verde (G) y Azul (B). Para leer y manipular im√°genes en Python, se pueden usar las librer√≠as `Pillow` (PIL), `matplotlib` y `numpy`. Esto permite acceder a los valores de los p√≠xeles y realizar an√°lisis o transformaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I=plt.imread(ruta+'imagen.bmp')\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I[0,0,0] # pixel (0,0) de la matriz roja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I[:,:,0],cmap='gray') # Matriz roja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=I.mean(axis=2)\n",
    "G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de aplicaciones en IA para cada tipo de archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîé Ejemplos de aplicaciones en IA para cada tipo de archivo\n",
    "\n",
    "### üìÑ Archivos de texto:\n",
    "\n",
    "- **An√°lisis de sentimientos:** Procesar opiniones de usuarios para determinar si son positivas o negativas.\n",
    "- **Extracci√≥n de palabras clave:** Identificar t√©rminos importantes en grandes vol√∫menes de texto.\n",
    "- **Procesamiento de lenguaje natural (NLP):** Tokenizaci√≥n, lematizaci√≥n y an√°lisis de frecuencia de palabras.\n",
    "- **An√°lisis de logs:** Detectar patrones o anomal√≠as en archivos de registro.\n",
    "- **Generaci√≥n autom√°tica de res√∫menes:** Resumir textos extensos con modelos de IA.\n",
    "- **Reconocimiento de entidades:** Extraer nombres de personas, lugares y organizaciones.\n",
    "- **Clasificaci√≥n de documentos:** Categorizar textos en temas o g√©neros.\n",
    "- **Traducci√≥n autom√°tica:** Convertir textos entre idiomas usando IA.\n",
    "\n",
    "### üìä Archivos Excel y CSV:\n",
    "\n",
    "- **An√°lisis exploratorio de datos (EDA):** Calcular totales, medias y tendencias.\n",
    "- **Preparaci√≥n de datos para ML:** Ingenier√≠a de caracter√≠sticas y limpieza de datos.\n",
    "- **Reportes automatizados:** Generar res√∫menes y exportar resultados.\n",
    "- **Detecci√≥n de anomal√≠as:** Identificar valores at√≠picos.\n",
    "- **Predicci√≥n de tendencias:** Series temporales para prever ventas.\n",
    "- **Segmentaci√≥n de clientes:** Agrupar clientes por patrones de compra.\n",
    "- **Visualizaci√≥n de datos:** Dashboards interactivos y gr√°ficos.\n",
    "\n",
    "### üñºÔ∏è Archivos de im√°genes RGB:\n",
    "\n",
    "- **Visi√≥n por computadora:** Clasificaci√≥n de im√°genes y reconocimiento facial.\n",
    "- **Procesamiento de im√°genes m√©dicas:** Detecci√≥n de regiones an√≥malas.\n",
    "- **Extracci√≥n de caracter√≠sticas visuales:** Histogramas y patrones de color.\n",
    "- **Detecci√≥n de objetos:** Localizaci√≥n y clasificaci√≥n en im√°genes.\n",
    "- **Reconstrucci√≥n 3D:** Modelos tridimensionales a partir de im√°genes.\n",
    "- **Segmentaci√≥n sem√°ntica:** Delimitaci√≥n de regiones espec√≠ficas.\n",
    "- **Realidad aumentada:** Superposici√≥n de informaci√≥n digital.\n",
    "\n",
    "### üóÇÔ∏è Archivos XML:\n",
    "\n",
    "- **Integraci√≥n de datos empresariales:** Extraer informaci√≥n de sistemas ERP.\n",
    "- **Procesamiento de datos IoT:** Leer registros de sensores.\n",
    "- **An√°lisis de publicaciones cient√≠ficas:** Obtener t√≠tulos y autores.\n",
    "- **Intercambio de datos entre aplicaciones:** Estandarizaci√≥n e interoperabilidad.\n",
    "- **Validaci√≥n de esquemas:** Verificar estructura y consistencia.\n",
    "- **Extracci√≥n de datos jer√°rquicos:** Navegaci√≥n en √°rboles complejos.\n",
    "- **Automatizaci√≥n de reportes:** Generar informes estructurados.\n",
    "\n",
    "### { } Archivos JSON:\n",
    "\n",
    "- **Consumo de APIs web:** Obtener y analizar datos en tiempo real.\n",
    "- **Almacenamiento y an√°lisis de logs:** Procesar registros de aplicaciones.\n",
    "- **An√°lisis de datos m√≥viles:** Leer resultados de encuestas y m√©tricas.\n",
    "- **Integraci√≥n de datos en tiempo real:** Sensores y dispositivos conectados.\n",
    "- **Visualizaci√≥n de datos:** Gr√°ficos y mapas interactivos.\n",
    "- **Entrenamiento de modelos de IA:** Datasets estructurados para algoritmos.\n",
    "- **Validaci√≥n y limpieza de datos:** Correcci√≥n de inconsistencias.\n",
    "\n",
    "### üó∫Ô∏è Archivos Shapefile (SHP):\n",
    "\n",
    "- **An√°lisis geoespacial:** Distancias y relaciones espaciales.\n",
    "- **Estudios ambientales y urbanos:** Distribuci√≥n de √°reas verdes y zonas urbanas.\n",
    "- **Modelado de redes y transporte:** Rutas √≥ptimas y predicci√≥n de tr√°fico.\n",
    "- **An√°lisis de riesgos naturales:** Identificaci√≥n de zonas vulnerables.\n",
    "- **Visualizaci√≥n de mapas tem√°ticos:** Datos demogr√°ficos y econ√≥micos.\n",
    "- **Optimizaci√≥n log√≠stica:** Rutas de entrega y distribuci√≥n.\n",
    "\n",
    "### üåê Archivos HTML:\n",
    "\n",
    "- **Web scraping:** Extracci√≥n de datos estructurados de p√°ginas web.\n",
    "- **Construcci√≥n de datasets:** Recolecci√≥n de informaci√≥n de m√∫ltiples p√°ginas.\n",
    "- **An√°lisis de enlaces:** Estructura de redes y relaciones.\n",
    "- **Extracci√≥n de tablas:** Datos tabulares para an√°lisis estad√≠stico.\n",
    "- **Monitoreo de precios:** Rastrear precios en tiendas en l√≠nea.\n",
    "- **An√°lisis de tendencias:** Identificar temas populares en blogs y noticias.\n",
    "- **Automatizaci√≥n de reportes web:** Generar informes autom√°ticos.\n",
    "- **Reconocimiento de patrones visuales:** Detecci√≥n de banners y anuncios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPqUYnWUof7Eo4SjyQR8MFR",
   "mount_file_id": "11cBGjZ8uzuVbqHGETC0huHCGxFz0MEeR",
   "provenance": [
    {
     "file_id": "11cBGjZ8uzuVbqHGETC0huHCGxFz0MEeR",
     "timestamp": 1660679616179
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
